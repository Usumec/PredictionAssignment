---
title: "Prediction Assignment"
author: "Andrea Musumeci"
date: "2/20/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Executive summary
Using data from the Weight Lifting Exercise Dataset ( http://groupware.les.inf.puc-rio.br/har), we build and validate a predictive algorithm to classify weight lifting exercises based on accelerometers measurements. The algorithm is used to classify a test set of 20 observations.

## Data preparation and cleanup
The training dataset is imported, and descriptive features and features with very few measurements are removed, as they constitute noise that could reduce the accuracy of our predictor.
```{r prep}
library(dplyr)
library(caret)

pml_train <- read.csv("pml-training.csv")

pml_train$classe <- factor(pml_train$classe)

# remove descriptive features
pml_train <- pml_train %>%
        select(-c(X, user_name, raw_timestamp_part_1, 
                  raw_timestamp_part_2, cvtd_timestamp, 
                  new_window, num_window))

# remove features with >95% NAs or empty values
keep <- sapply(pml_train, function(x) mean(!is.na(x))) > .95
pml_train <- pml_train[, keep]
keep <- sapply(pml_train, function(x) mean(x != "")) > .95
pml_train <- pml_train[, keep]
```

## Model fitting
After cleanup, the dataset is partitioned into training and testing set, and a model is fitted to the training set.

In this case, we choose a random forest algorithm, as it is a powerful classificator with built-in feature selection. We implement a k-fold (k=3) crossvalidation using `trainControl`.
```{r train, cache=TRUE}
#ensure reproducibility
set.seed(42)

# partition data
inTrain <- createDataPartition(pml_train$classe, p = .7, list = F)
trainDS <- pml_train[inTrain,]
testDS <- pml_train[-inTrain,]

#train model Random Forest using built-in cross validation control
ctrlRF <- trainControl(method = "cv", number = 3, verboseIter = F)
model <- train(classe ~., data = trainDS, method = "rf", trControl = ctrlRF)
model$finalModel
```

## Validation and accuracy estimate
We test our fitted model against the testing set, and measure accuracy using the `confusionMatrix` function.
```{r validate}
# predictions and accuracy measures
predictions <- predict(model, newdata = testDS)
conf <- confusionMatrix(predictions, testDS$classe)
```
With an accuracy of `r round(conf$overall[1],3)`, we can estimate an out-of-sample error of <`r (1-round(conf$overall[1],2))*100`%.

## Predictions
Finally, we apply the model to predict the categories of the 20 test data points.
```{r predict}
# Test data
pml_test <- read.csv("pml-testing.csv")
predict(model, newdata = pml_test)
```